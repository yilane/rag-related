"""
ICD-10æ•°æ®åº“æ„å»ºæ¨¡å—
"""

import os
import pandas as pd
import numpy as np
from typing import List, Dict, Any
from sentence_transformers import SentenceTransformer
from tqdm import tqdm
import logging

from config import EMBEDDING_CONFIG, PROCESSING_CONFIG
from milvus_service import MilvusService

logging.basicConfig(level=getattr(logging, PROCESSING_CONFIG['log_level']))
logger = logging.getLogger(__name__)


class ICD10Vectorizer:
    """ICD-10æ–‡æœ¬å‘é‡åŒ–å™¨"""
    
    def __init__(self, model_name: str = None):
        self.model_name = model_name or EMBEDDING_CONFIG['model_name']
        self.dimension = EMBEDDING_CONFIG['dimension']
        self.batch_size = EMBEDDING_CONFIG['batch_size']
        self.model = None
        self._load_model()
    
    def _load_model(self):
        """åŠ è½½å‘é‡åŒ–æ¨¡å‹"""
        try:
            logger.info(f"æ­£åœ¨åŠ è½½å‘é‡åŒ–æ¨¡å‹: {self.model_name}")
            self.model = SentenceTransformer(self.model_name)
            logger.info(f"æ¨¡å‹åŠ è½½å®Œæˆï¼Œå‘é‡ç»´åº¦: {self.dimension}")
        except Exception as e:
            logger.error(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def encode(self, texts: List[str]) -> np.ndarray:
        """æ–‡æœ¬å‘é‡åŒ–"""
        try:
            if not texts:
                return np.array([])
            
            logger.info(f"å¼€å§‹å‘é‡åŒ–å¤„ç†ï¼Œæ–‡æœ¬æ•°é‡: {len(texts)}")
            
            vectors = self.model.encode(
                texts, 
                batch_size=self.batch_size,
                show_progress_bar=True,
                normalize_embeddings=True,
                convert_to_numpy=True
            )
            
            logger.info(f"å‘é‡åŒ–å®Œæˆï¼Œè¾“å‡ºå½¢çŠ¶: {vectors.shape}")
            return vectors
            
        except Exception as e:
            logger.error(f"å‘é‡åŒ–å¤„ç†å¤±è´¥: {e}")
            raise
    
    def cleanup_resources(self) -> bool:
        """æ¸…ç†å‘é‡åŒ–æ¨¡å‹èµ„æº"""
        try:
            logger.info("æ­£åœ¨æ¸…ç†å‘é‡åŒ–æ¨¡å‹èµ„æº...")
            
            # æ¸…ç†SentenceTransformeræ¨¡å‹
            if hasattr(self, 'model') and self.model is not None:
                # æ¸…ç†æ¨¡å‹ç»„ä»¶
                if hasattr(self.model, '_modules'):
                    del self.model._modules
                if hasattr(self.model, 'tokenizer'):
                    del self.model.tokenizer
                del self.model
                self.model = None
            
            # å°è¯•æ¸…ç†CUDAç¼“å­˜
            try:
                import torch
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    logger.info("å‘é‡åŒ–æ¨¡å‹CUDAç¼“å­˜å·²æ¸…ç†")
            except ImportError:
                pass
            
            logger.info("å‘é‡åŒ–æ¨¡å‹èµ„æºæ¸…ç†å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"æ¸…ç†å‘é‡åŒ–èµ„æºå¤±è´¥: {e}")
            return False
    
    def __del__(self):
        """ææ„å‡½æ•°ï¼šç¡®ä¿èµ„æºè¢«æ¸…ç†"""
        try:
            self.cleanup_resources()
        except:
            pass


class DatabaseBuilder:
    """æ•°æ®åº“æ„å»ºå™¨"""
    
    def __init__(self):
        self.vectorizer = ICD10Vectorizer()
        self.milvus_service = MilvusService()
        self.chunk_size = PROCESSING_CONFIG['chunk_size']
    
    def load_csv_data(self, csv_path: str) -> pd.DataFrame:
        """åŠ è½½CSVæ•°æ®"""
        try:
            logger.info(f"æ­£åœ¨åŠ è½½CSVæ–‡ä»¶: {csv_path}")
            
            if not os.path.exists(csv_path):
                raise FileNotFoundError(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
            
            df = pd.read_csv(csv_path, encoding='utf-8')
            df = df.dropna(subset=['ç–¾ç—…ç¼–ç ', 'ç–¾ç—…åç§°'])
            df = df.drop_duplicates(subset=['ç–¾ç—…ç¼–ç '])
            
            logger.info(f"CSVåŠ è½½å®Œæˆï¼ŒåŸå§‹æ•°æ®: {len(df)}æ¡è®°å½•")
            
            logger.info("æ•°æ®æ ·æœ¬:")
            for col in df.columns:
                logger.info(f"  {col}: {df[col].iloc[0] if not df.empty else 'N/A'}")
            
            return df
            
        except Exception as e:
            logger.error(f"åŠ è½½CSVæ–‡ä»¶å¤±è´¥: {e}")
            raise
    
    def generate_descriptions(self, df: pd.DataFrame) -> List[str]:
        """ç”Ÿæˆæè¿°æ–‡æœ¬"""
        try:
            logger.info("å¼€å§‹ç”Ÿæˆæè¿°æ–‡æœ¬...")
            
            descriptions = []
            for _, row in tqdm(df.iterrows(), total=len(df), desc="ç”Ÿæˆæè¿°"):
                parts = []
                
                if pd.notna(row.get('ç« åç§°')):
                    parts.append(f"åˆ†ç±»: {row['ç« åç§°']}")
                
                if pd.notna(row.get('èŠ‚åç§°')):
                    parts.append(f"ç±»åˆ«: {row['èŠ‚åç§°']}")
                
                if pd.notna(row.get('ä¸‰ä½åç§°')):
                    parts.append(f"ç–¾ç—…ç»„: {row['ä¸‰ä½åç§°']}")
                
                if pd.notna(row.get('å››ä½åç§°')) and row.get('å››ä½åç§°') != row.get('ç–¾ç—…åç§°'):
                    parts.append(f"äºšå‹: {row['å››ä½åç§°']}")
                
                parts.append(f"ç–¾ç—…: {row['ç–¾ç—…åç§°']}")
                parts.append(f"ç¼–ç : {row['ç–¾ç—…ç¼–ç ']}")
                
                description = " | ".join(parts)
                descriptions.append(description)
            
            logger.info(f"æè¿°æ–‡æœ¬ç”Ÿæˆå®Œæˆï¼Œå…±{len(descriptions)}æ¡")
            
            if descriptions:
                logger.info(f"æè¿°ç¤ºä¾‹: {descriptions[0]}")
            
            return descriptions
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæè¿°æ–‡æœ¬å¤±è´¥: {e}")
            raise
    
    def prepare_entities(self, df: pd.DataFrame, descriptions: List[str], vectors: np.ndarray) -> List[Dict[str, Any]]:
        """å‡†å¤‡æ’å…¥å®ä½“æ•°æ®"""
        try:
            logger.info("å¼€å§‹å‡†å¤‡å…¥åº“æ•°æ®...")
            
            entities = []
            for i, (_, row) in enumerate(tqdm(df.iterrows(), total=len(df), desc="å‡†å¤‡æ•°æ®")):
                entity = {
                    'disease_code': str(row['ç–¾ç—…ç¼–ç ']),
                    'disease_name': str(row['ç–¾ç—…åç§°']),
                    'description_text': descriptions[i],
                    'embedding_vector': vectors[i].tolist(),
                    'chapter_name': str(row.get('ç« åç§°', '')),
                    'section_name': str(row.get('èŠ‚åç§°', ''))
                }
                entities.append(entity)
            
            logger.info(f"æ•°æ®å‡†å¤‡å®Œæˆï¼Œå…±{len(entities)}æ¡è®°å½•")
            return entities
            
        except Exception as e:
            logger.error(f"å‡†å¤‡å…¥åº“æ•°æ®å¤±è´¥: {e}")
            raise
    
    def build_database(self, csv_path: str) -> Dict[str, Any]:
        """å®Œæ•´çš„æ•°æ®åº“æ„å»ºæµç¨‹"""
        try:
            logger.info("ğŸš€ å¼€å§‹æ„å»ºICD-10å‘é‡æ•°æ®åº“...")
            
            df = self.load_csv_data(csv_path)
            descriptions = self.generate_descriptions(df)
            vectors = self.vectorizer.encode(descriptions)
            entities = self.prepare_entities(df, descriptions, vectors)
            
            logger.info("ğŸ“Š åˆ›å»ºMilvusé›†åˆ...")
            if not self.milvus_service.create_collection():
                raise Exception("åˆ›å»ºMilvusé›†åˆå¤±è´¥")
            
            if not self.milvus_service.create_index():
                raise Exception("åˆ›å»ºMilvusç´¢å¼•å¤±è´¥")
            
            logger.info("ğŸ’¾ å¼€å§‹æ’å…¥æ•°æ®åˆ°Milvus...")
            
            total_inserted = 0
            for i in range(0, len(entities), self.chunk_size):
                chunk = entities[i:i + self.chunk_size]
                if self.milvus_service.insert_data(chunk):
                    total_inserted += len(chunk)
                    logger.info(f"å·²æ’å…¥: {total_inserted}/{len(entities)}")
                else:
                    logger.error(f"æ’å…¥ç¬¬{i//self.chunk_size + 1}æ‰¹æ•°æ®å¤±è´¥")
            
            logger.info("ğŸ”„ åŠ è½½é›†åˆåˆ°å†…å­˜...")
            if not self.milvus_service.load_collection():
                logger.warning("åŠ è½½é›†åˆåˆ°å†…å­˜å¤±è´¥ï¼Œä½†æ•°æ®å·²æ’å…¥æˆåŠŸ")
            
            stats = self.milvus_service.get_collection_stats()
            
            result = {
                'success': True,
                'total_records': len(entities),
                'inserted_records': total_inserted,
                'vector_dimension': self.vectorizer.dimension,
                'collection_stats': stats,
                'csv_path': csv_path
            }
            
            logger.info("ğŸ‰ æ•°æ®åº“æ„å»ºå®Œæˆï¼")
            logger.info(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯: {result}")
            
            return result
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“æ„å»ºå¤±è´¥: {e}")
            return {
                'success': False,
                'error': str(e),
                'csv_path': csv_path
            }


def main():
    """ä¸»å‡½æ•°ï¼šæ„å»ºICD-10å‘é‡æ•°æ®åº“"""
    try:
        csv_path = "data/ICD-10åŒ»ä¿1.0ç‰ˆ.csv"
        
        if not os.path.exists(csv_path):
            print(f"âŒ CSVæ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
            print("è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶åœ¨æ­£ç¡®çš„ä½ç½®")
            return
        
        builder = DatabaseBuilder()
        result = builder.build_database(csv_path)
        
        if result['success']:
            print("\nğŸ‰ æ•°æ®åº“æ„å»ºæˆåŠŸ!")
            print(f"ğŸ“Š æ€»è®°å½•æ•°: {result['total_records']}")
            print(f"ğŸ’¾ å·²æ’å…¥è®°å½•: {result['inserted_records']}")
            print(f"ğŸ”¢ å‘é‡ç»´åº¦: {result['vector_dimension']}")
            print(f"ğŸ“ˆ é›†åˆç»Ÿè®¡: {result['collection_stats']['num_entities']}æ¡è®°å½•")
            
            print("\nâœ… æ•°æ®åº“æ„å»ºå®Œæˆï¼Œå¯ä»¥å¼€å§‹ä½¿ç”¨æ£€ç´¢åŠŸèƒ½!")
            
        else:
            print(f"\nâŒ æ•°æ®åº“æ„å»ºå¤±è´¥: {result['error']}")
            
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"\nâŒ æ‰§è¡Œå¤±è´¥: {e}")


if __name__ == "__main__":
    main()