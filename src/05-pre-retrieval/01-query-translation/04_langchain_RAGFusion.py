"""
ä½¿ç”¨RAG-Fusionè¿›è¡Œå¢å¼ºå‹å¤šæŸ¥è¯¢æ£€ç´¢
åœ¨å¤šæŸ¥è¯¢åŸºç¡€ä¸Šå¢åŠ æ™ºèƒ½æ’åºï¼Œæä¾›æœ€ä¼˜åŒ–çš„æ£€ç´¢ç»“æœ
"""

import logging
import os
from dotenv import load_dotenv
from langchain.retrievers.multi_query import MultiQueryRetriever
from langchain_chroma import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_deepseek import ChatDeepSeek
from langchain_huggingface import HuggingFaceEmbeddings

# åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡ï¼ŒåŒ…æ‹¬APIå¯†é’¥ç­‰æ•æ„Ÿä¿¡æ¯
load_dotenv()

# è®¾ç½®æ—¥å¿—è®°å½•ï¼ŒæŸ¥çœ‹å¤šæŸ¥è¯¢ç”Ÿæˆè¿‡ç¨‹
logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
multi_query_logger = logging.getLogger("langchain.retrievers.multi_query")
multi_query_logger.setLevel(logging.DEBUG)

print("\nğŸ“š æ­£åœ¨åŠ è½½æ–‡æ¡£æ•°æ®...")
# ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•çš„æ•°æ®æ–‡ä»¶
loader = TextLoader("data/txt/ç³–å°¿ç—….txt", encoding="utf-8")
data = loader.load()
print("âœ… æ–‡æ¡£åŠ è½½å®Œæˆ")

# æ–‡æœ¬åˆ†å—
text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)
all_splits = text_splitter.split_documents(data)

# å‘é‡å­˜å‚¨
print("\nğŸ”¤ æ­£åœ¨æ„å»ºå‘é‡å­˜å‚¨...")
embed_model = HuggingFaceEmbeddings(model_name="BAAI/bge-small-zh")
vectorstore = Chroma.from_documents(documents=all_splits, embedding=embed_model)
print("âœ… å‘é‡å­˜å‚¨æ„å»ºå®Œæˆ")

# è®¾ç½®LLM
llm = ChatDeepSeek(
    model="deepseek-chat", temperature=0.1, api_key=os.getenv("DEEPSEEK_API_KEY")
)

# åˆ›å»ºRAG-Fusionæ£€ç´¢å™¨ï¼ˆåŸºäºMultiQueryRetrieverçš„å¢å¼ºç‰ˆï¼‰
print("\nğŸ› ï¸ æ­£åœ¨è®¾ç½®æ£€ç´¢å™¨...")

class RAGFusionRetriever(MultiQueryRetriever):
    """RAG-Fusionæ£€ç´¢å™¨ï¼šç»§æ‰¿MultiQueryRetrieverå¹¶æ·»åŠ RRFæ’åº"""
    
    def reciprocal_rank_fusion(self, results: list, k=60):
        """RRFç®—æ³•ï¼šå¯¹å¤šä¸ªæ£€ç´¢ç»“æœè¿›è¡Œèåˆæ’åº"""
        fused_scores = {}
        
        # éå†æ¯ä¸ªæŸ¥è¯¢çš„æ£€ç´¢ç»“æœ
        for docs in results:
            # éå†æ–‡æ¡£åŠå…¶æ’åä½ç½®
            for rank, doc in enumerate(docs):
                # å°†æ–‡æ¡£è½¬æ¢ä¸ºå­—ç¬¦ä¸²ä½œä¸ºé”®
                doc_str = doc.page_content
                # å¦‚æœæ–‡æ¡£ä¸åœ¨èåˆåˆ†æ•°å­—å…¸ä¸­ï¼Œæ·»åŠ åˆå§‹åˆ†æ•°0
                if doc_str not in fused_scores:
                    fused_scores[doc_str] = {"score": 0, "doc": doc}
                # ä½¿ç”¨RRFå…¬å¼æ›´æ–°åˆ†æ•°: 1 / (rank + k)
                fused_scores[doc_str]["score"] += 1 / (rank + k)
        
        # æŒ‰èåˆåˆ†æ•°é™åºæ’åº
        sorted_results = sorted(fused_scores.values(), key=lambda x: x["score"], reverse=True)
        return [item["doc"] for item in sorted_results]
    
    def _get_relevant_documents(self, query: str, **kwargs):
        """é‡å†™æ£€ç´¢æ–¹æ³•ï¼Œå¢åŠ RRFèåˆæ’åº"""
        print("ğŸ”„ æ­¥éª¤1: MultiQueryRetrieverç”Ÿæˆå¤šä¸ªæŸ¥è¯¢...")
        
        # ä½¿ç”¨çˆ¶ç±»çš„å®Œæ•´æ£€ç´¢é€»è¾‘å…ˆè·å–æ‰€æœ‰æŸ¥è¯¢çš„ç»“æœ
        # ä½†æˆ‘ä»¬éœ€è¦åˆ†æ­¥éª¤æ¥å±•ç¤ºè¿‡ç¨‹ï¼Œæ‰€ä»¥ç›´æ¥è°ƒç”¨çˆ¶ç±»æ–¹æ³•è·å–ç»“æœ
        from langchain_core.callbacks.manager import CallbackManagerForRetrieverRun
        run_manager = CallbackManagerForRetrieverRun.get_noop_manager()
        
        # ç”Ÿæˆå¤šä¸ªæŸ¥è¯¢
        queries = self.generate_queries(query, run_manager)
        print(f"   ç”Ÿæˆäº† {len(queries)} ä¸ªæŸ¥è¯¢å˜ä½“:")
        for i, q in enumerate(queries, 1):
            print(f"   [{i}] {q}")
        
        print("\nğŸ” æ­¥éª¤2: æ‰§è¡Œå¤šæŸ¥è¯¢æ£€ç´¢...")
        # å¯¹æ¯ä¸ªæŸ¥è¯¢åˆ†åˆ«æ£€ç´¢
        all_results = []
        for i, q in enumerate(queries, 1):
            docs = self.retriever.get_relevant_documents(q)
            print(f"   æŸ¥è¯¢{i}æ£€ç´¢åˆ° {len(docs)} ä¸ªæ–‡æ¡£")
            all_results.append(docs)
        
        print("\nğŸ“Š æ­¥éª¤3: RRFèåˆæ’åº...")
        # ä½¿ç”¨RRFç®—æ³•èåˆæ’åº
        if all_results:
            fused_docs = self.reciprocal_rank_fusion(all_results, k=60)
            print(f"   RRFèåˆå®Œæˆï¼Œè¿”å›å‰3ä¸ªæœ€ç›¸å…³æ–‡æ¡£")
            return fused_docs[:3]
        
        return []

# åˆ›å»ºRAG-Fusionæ£€ç´¢å™¨
base_retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
rag_fusion_retriever = RAGFusionRetriever.from_llm(
    retriever=base_retriever,
    llm=llm
)
print("âœ… RAG-Fusionæ£€ç´¢å™¨è®¾ç½®å®Œæˆ")

query = "ç³–å°¿ç—…çš„å¹¶å‘ç—‡æœ‰å“ªäº›ï¼Ÿ"

print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: ã€Œ{query}ã€")
print("ğŸš€ å¼€å§‹RAG-Fusionæ£€ç´¢...")

# ä½¿ç”¨RAG-Fusionæ£€ç´¢å™¨è¿›è¡Œæ£€ç´¢
docs = rag_fusion_retriever.invoke(query)

print(f"\nğŸ“„ RAG-Fusionæ£€ç´¢ç»“æœ:")
if isinstance(docs, list):
    for i, doc in enumerate(docs, 1):
        content = doc.page_content if hasattr(doc, "page_content") else str(doc)
        preview = content.replace('\n', ' ').strip()
        if len(preview) > 150:
            preview = preview[:150] + "..."
        print(f"[{i}] {preview}")
else:
    print("âŒ æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")

print(f"\nâœ… RAG-Fusionæ£€ç´¢å®Œæˆï¼ä½¿ç”¨RRFç®—æ³•è¿”å› {len(docs) if isinstance(docs, list) else 0} ä¸ªæœ€ç›¸å…³æ–‡æ¡£")

