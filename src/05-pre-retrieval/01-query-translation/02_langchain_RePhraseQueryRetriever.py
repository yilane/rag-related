"""
ä½¿ç”¨LangChainçš„RePhraseQueryRetrieverè¿›è¡ŒæŸ¥è¯¢é‡å†™å¯¹æ¯”
å±•ç¤ºæŸ¥è¯¢é‡å†™å¯¹æ£€ç´¢æ•ˆæœçš„æ”¹è¿›ä½œç”¨
"""

import logging
import os
from dotenv import load_dotenv
from langchain.retrievers import RePhraseQueryRetriever
from langchain_chroma import Chroma
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_deepseek import ChatDeepSeek
from langchain_huggingface import HuggingFaceEmbeddings

# åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡ï¼ŒåŒ…æ‹¬APIå¯†é’¥ç­‰æ•æ„Ÿä¿¡æ¯
load_dotenv()

# è®¾ç½®æ—¥å¿—è®°å½•ï¼Œå¯ä»¥çœ‹åˆ°æŸ¥è¯¢é‡å†™çš„å…·ä½“è¿‡ç¨‹
logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
logger = logging.getLogger("langchain.retrievers.re_phraser")
logger.setLevel(logging.INFO)

print("\nğŸ“š æ­£åœ¨åŠ è½½æ–‡æ¡£æ•°æ®...")
# ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•çš„æ•°æ®æ–‡ä»¶
loader = TextLoader("data/txt/ç³–å°¿ç—….txt", encoding="utf-8")
data = loader.load()
print("âœ… æ–‡æ¡£åŠ è½½å®Œæˆ")

# æ–‡æœ¬åˆ†å—
text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)
all_splits = text_splitter.split_documents(data)

# å‘é‡å­˜å‚¨
print("\nğŸ”¤ æ­£åœ¨æ„å»ºå‘é‡å­˜å‚¨...")
embed_model = HuggingFaceEmbeddings(model_name="BAAI/bge-small-zh")
vectorstore = Chroma.from_documents(documents=all_splits, embedding=embed_model)
print("âœ… å‘é‡å­˜å‚¨æ„å»ºå®Œæˆ")

# è®¾ç½®LLM
llm = ChatDeepSeek(
    model="deepseek-chat", temperature=0, api_key=os.getenv("DEEPSEEK_API_KEY")
)

# åˆ›å»ºé‡å†™æ£€ç´¢å™¨
print("\nğŸ› ï¸ æ­£åœ¨è®¾ç½®æ£€ç´¢å™¨...")
rewrite_retriever = RePhraseQueryRetriever.from_llm(
    retriever=vectorstore.as_retriever(search_kwargs={"k": 3}), llm=llm
)
print("âœ… æ£€ç´¢å™¨è®¾ç½®å®Œæˆ")

query = "è¡€ç³–é«˜äº†æ€ä¹ˆåŠï¼Ÿ"

print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢: ã€Œ{query}ã€")
print("ğŸ”„ æ­£åœ¨è¿›è¡ŒæŸ¥è¯¢é‡å†™å’Œæ£€ç´¢...")

# ä½¿ç”¨RePhraseQueryRetrieverè¿›è¡ŒæŸ¥è¯¢é‡å†™å’Œæ£€ç´¢
docs = rewrite_retriever.invoke(query)

print(f"\nğŸ“„ æ£€ç´¢åˆ°çš„æ–‡æ¡£ç‰‡æ®µ:")
if isinstance(docs, list):
    for i, doc in enumerate(docs, 1):
        content = doc.page_content if hasattr(doc, "page_content") else str(doc)
        preview = content.replace('\n', ' ').strip()
        if len(preview) > 150:
            preview = preview[:150] + "..."
        print(f"[{i}] {preview}")
else:
    print("âŒ æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")

print(f"\nâœ… æŸ¥è¯¢é‡å†™æ£€ç´¢å®Œæˆï¼æ£€ç´¢åˆ° {len(docs) if isinstance(docs, list) else 0} ä¸ªç›¸å…³æ–‡æ¡£")
