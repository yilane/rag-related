# -*- coding: utf-8 -*-
"""
å°çº¢ä¹¦çƒ­ç‚¹æ–°é—»Self-Query Retrieverç¤ºä¾‹
ä½¿ç”¨æ¨¡æ‹Ÿçš„å°çº¢ä¹¦çƒ­ç‚¹æ–°é—»æ•°æ®æ¼”ç¤ºè‡ªæŸ¥è¯¢æ£€ç´¢åŠŸèƒ½
"""

from langchain_deepseek import ChatDeepSeek
from langchain_core.documents import Document
from langchain.chains.query_constructor.base import AttributeInfo
from langchain.retrievers.self_query.base import SelfQueryRetriever
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from pydantic import BaseModel, Field
import os
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# å®šä¹‰æ–°é—»å…ƒæ•°æ®æ¨¡å‹
class NewsMetadata(BaseModel):
    """å°çº¢ä¹¦æ–°é—»å…ƒæ•°æ®æ¨¡å‹ï¼Œå®šä¹‰äº†éœ€è¦æå–çš„æ–°é—»å±æ€§"""

    title: str = Field(description="æ–°é—»æ ‡é¢˜")
    category: str = Field(description="æ–°é—»åˆ†ç±»")
    author: str = Field(description="ä½œè€…æ˜µç§°")
    likes_count: int = Field(description="ç‚¹èµæ•°")
    comments_count: int = Field(description="è¯„è®ºæ•°")
    shares_count: int = Field(description="åˆ†äº«æ•°")
    publish_date: str = Field(description="å‘å¸ƒæ—¥æœŸ")
    tags: str = Field(description="æ ‡ç­¾ï¼Œå¤šä¸ªæ ‡ç­¾ç”¨é€—å·åˆ†éš”")
    region: str = Field(description="åœ°åŒº")


# åˆ›å»ºæ¨¡æ‹Ÿçš„å°çº¢ä¹¦çƒ­ç‚¹æ–°é—»æ•°æ®
def create_mock_news_data():
    """åˆ›å»ºæ¨¡æ‹Ÿçš„å°çº¢ä¹¦çƒ­ç‚¹æ–°é—»æ•°æ®"""

    # æ¨¡æ‹Ÿæ–°é—»æ•°æ®
    mock_news = [
        {
            "title": "2024å¹´æœ€ç«çˆ†çš„æŠ¤è‚¤å“æ¨èï¼Œæ•æ„Ÿè‚Œå¿…å¤‡ï¼",
            "content": "ä»Šå¹´æœ€å—æ¬¢è¿çš„æŠ¤è‚¤å“ç›˜ç‚¹ï¼ŒåŒ…æ‹¬ç¥ä»™æ°´ã€SK-IIç²¾åã€å…°è”»å°é»‘ç“¶ç­‰ï¼Œç‰¹åˆ«é€‚åˆæ•æ„Ÿè‚Œä½¿ç”¨ï¼Œäº²æµ‹æœ‰æ•ˆï¼",
            "category": "ç¾å¦†æŠ¤è‚¤",
            "author": "ç¾å¦†å°è¾¾äººAmy",
            "likes_count": 15680,
            "comments_count": 890,
            "shares_count": 456,
            "publish_date": "2024-03-15",
            "publish_day": 15,
            "tags": "æŠ¤è‚¤,æ•æ„Ÿè‚Œ,ç¾å¦†æ¨è",
            "region": "ä¸Šæµ·",
        },
        {
            "title": "æˆéƒ½å¿…åƒç«é”…åº—TOP10ï¼Œæœ¬åœ°äººæ¨èï¼",
            "content": "æˆéƒ½ç«é”…åº—æ·±åº¦æµ‹è¯„ï¼Œä»è€ç‰Œç«é”…åˆ°ç½‘çº¢æ–°åº—ï¼ŒåŒ…æ‹¬æµ·åº•æã€èœ€å¤§ä¾ ã€å°é¾™åç­‰ï¼Œæ¯ä¸€å®¶éƒ½æœ‰ç‹¬ç‰¹é£å‘³ã€‚",
            "category": "ç¾é£Ÿæ¢åº—",
            "author": "æˆéƒ½åƒè´§ç‹",
            "likes_count": 28900,
            "comments_count": 1245,
            "shares_count": 789,
            "publish_date": "2024-03-10",
            "publish_day": 10,
            "tags": "æˆéƒ½ç¾é£Ÿ,ç«é”…,æ¢åº—æ¨è",
            "region": "æˆéƒ½",
        },
        {
            "title": "æ˜¥å­£ç©¿æ­æŒ‡å—ï¼šæ¸©æŸ”ç³»å¥³ç”Ÿå¿…çœ‹æ­é…æŠ€å·§",
            "content": "æ˜¥å¤©æ¥äº†ï¼Œåˆ†äº«ä¸€äº›æ¸©æŸ”ç³»ç©¿æ­æŠ€å·§ï¼ŒåŒ…æ‹¬è‰²å½©æ­é…ã€å•å“é€‰æ‹©ã€é…é¥°è¿ç”¨ç­‰ï¼Œè®©ä½ è½»æ¾ç©¿å‡ºä¼˜é›…æ°”è´¨ã€‚",
            "category": "æ—¶å°šç©¿æ­",
            "author": "æ—¶å°šåšä¸»Lily",
            "likes_count": 12450,
            "comments_count": 567,
            "shares_count": 334,
            "publish_date": "2024-03-12",
            "publish_day": 12,
            "tags": "ç©¿æ­,æ˜¥å­£æ­é…,æ¸©æŸ”é£",
            "region": "åŒ—äº¬",
        },
        {
            "title": "æ—¥æœ¬æ¨±èŠ±å­£æ—…æ¸¸æ”»ç•¥ï¼Œæœ€ä½³èµæ¨±åœ°ç‚¹æ¨è",
            "content": "2024å¹´æ—¥æœ¬æ¨±èŠ±å­£å³å°†åˆ°æ¥ï¼Œåˆ†äº«æœ€ä½³èµæ¨±åœ°ç‚¹ã€äº¤é€šæ”»ç•¥ã€ä½å®¿å»ºè®®ï¼Œè®©ä½ çš„æ—¥æœ¬ä¹‹è¡Œå®Œç¾æ— ç¼ºã€‚",
            "category": "æ—…æ¸¸æ”»ç•¥",
            "author": "æ—…è¡Œè¾¾äººå°ç‹",
            "likes_count": 45600,
            "comments_count": 2100,
            "shares_count": 1560,
            "publish_date": "2024-03-08",
            "publish_day": 8,
            "tags": "æ—¥æœ¬æ—…æ¸¸,æ¨±èŠ±å­£,æ—…æ¸¸æ”»ç•¥",
            "region": "å¹¿å·",
        },
        {
            "title": "å±…å®¶å¥èº«å¿…å¤‡å™¨ææ¨èï¼Œå°ç©ºé—´å¤§æ•ˆæœ",
            "content": "ç–«æƒ…æ—¶ä»£å±…å®¶å¥èº«æˆä¸ºè¶‹åŠ¿ï¼Œæ¨èå‡ æ¬¾å®ç”¨çš„å¥èº«å™¨æï¼ŒåŒ…æ‹¬ç‘œä¼½å«ã€å“‘é“ƒã€å¼¹åŠ›å¸¦ç­‰ï¼Œé€‚åˆå°æˆ·å‹ä½¿ç”¨ã€‚",
            "category": "å¥èº«è¿åŠ¨",
            "author": "å¥èº«æ•™ç»ƒMark",
            "likes_count": 8760,
            "comments_count": 432,
            "shares_count": 198,
            "publish_date": "2024-03-13",
            "publish_day": 13,
            "tags": "å¥èº«,å±…å®¶è¿åŠ¨,å™¨ææ¨è",
            "region": "æ·±åœ³",
        },
        {
            "title": "å¤§å­¦ç”Ÿå¿…å¤‡æ•°ç äº§å“æ¸…å•ï¼Œæ€§ä»·æ¯”ä¹‹é€‰",
            "content": "ä¸ºå¤§å­¦ç”Ÿæ¨èæ€§ä»·æ¯”è¶…é«˜çš„æ•°ç äº§å“ï¼ŒåŒ…æ‹¬ç¬”è®°æœ¬ç”µè„‘ã€å¹³æ¿ã€è€³æœºã€å……ç”µå®ç­‰ï¼Œå­¦ä¹ ç”Ÿæ´»ä¸¤ä¸è¯¯ã€‚",
            "category": "æ•°ç ç§‘æŠ€",
            "author": "æ•°ç è¯„æµ‹å¸ˆLeo",
            "likes_count": 19800,
            "comments_count": 756,
            "shares_count": 445,
            "publish_date": "2024-03-11",
            "publish_day": 11,
            "tags": "æ•°ç äº§å“,å¤§å­¦ç”Ÿ,æ€§ä»·æ¯”",
            "region": "æ­å·",
        },
        {
            "title": "æ–°æ‰‹å…»çŒ«å®Œå…¨æŒ‡å—ï¼Œä»é€‰çŒ«åˆ°å…»æŠ¤å…¨æ”»ç•¥",
            "content": "ç¬¬ä¸€æ¬¡å…»çŒ«éœ€è¦æ³¨æ„ä»€ä¹ˆï¼Ÿä»çŒ«å’ªå“ç§é€‰æ‹©ã€å¿…å¤‡ç”¨å“ã€å–‚å…»æ–¹æ³•åˆ°å¥åº·æŠ¤ç†ï¼Œæ–°æ‰‹é“²å±å®˜å¿…çœ‹æŒ‡å—ã€‚",
            "category": "å® ç‰©ç”Ÿæ´»",
            "author": "çŒ«å’ªä¸“å®¶Sarah",
            "likes_count": 13560,
            "comments_count": 689,
            "shares_count": 287,
            "publish_date": "2024-03-14",
            "publish_day": 14,
            "tags": "å…»çŒ«,å® ç‰©æŠ¤ç†,æ–°æ‰‹æŒ‡å—",
            "region": "å—äº¬",
        },
        {
            "title": "èŒåœºæ–°äººå¿…å¤‡æŠ€èƒ½ï¼Œå¦‚ä½•å¿«é€Ÿé€‚åº”å·¥ä½œç¯å¢ƒ",
            "content": "åˆå…¥èŒåœºå¦‚ä½•å¿«é€Ÿèå…¥å›¢é˜Ÿï¼Ÿåˆ†äº«èŒåœºæ²Ÿé€šæŠ€å·§ã€å·¥ä½œæ•ˆç‡æå‡æ–¹æ³•ã€èŒä¸šå½¢è±¡å¡‘é€ ç­‰å®ç”¨å»ºè®®ã€‚",
            "category": "èŒåœºå¹²è´§",
            "author": "èŒåœºå¯¼å¸ˆAnna",
            "likes_count": 22100,
            "comments_count": 980,
            "shares_count": 567,
            "publish_date": "2024-03-09",
            "publish_day": 9,
            "tags": "èŒåœºæŠ€èƒ½,æ–°äººæŒ‡å—,å·¥ä½œç»éªŒ",
            "region": "è‹å·",
        },
    ]

    # å°†æ•°æ®è½¬æ¢ä¸ºDocumentå¯¹è±¡
    documents = []
    for news in mock_news:
        metadata = {key: value for key, value in news.items() if key != "content"}
        doc = Document(page_content=news["content"], metadata=metadata)
        documents.append(doc)

    return documents


# ä¸»ç¨‹åº
def main():
    print("=== å°çº¢ä¹¦çƒ­ç‚¹æ–°é—» Self-Query Retriever ç¤ºä¾‹ ===\n")

    # åˆ›å»ºæ¨¡æ‹Ÿæ–°é—»æ•°æ®
    print("ğŸ“° æ­£åœ¨åŠ è½½å°çº¢ä¹¦çƒ­ç‚¹æ–°é—»æ•°æ®...")
    news_docs = create_mock_news_data()
    print(f"âœ… æˆåŠŸåŠ è½½ {len(news_docs)} æ¡æ–°é—»æ•°æ®\n")

    # æ˜¾ç¤ºåŠ è½½çš„æ–°é—»æ ‡é¢˜
    print("ğŸ“‹ å·²åŠ è½½çš„æ–°é—»åˆ—è¡¨ï¼š")
    for i, doc in enumerate(news_docs, 1):
        print(f"{i}. {doc.metadata['title']}")
    print()

    # åˆ›å»ºå‘é‡å­˜å‚¨
    print("ğŸ”„ æ­£åœ¨åˆ›å»ºå‘é‡å­˜å‚¨...")
    embed_model = HuggingFaceEmbeddings(model_name="BAAI/bge-small-zh")
    vectorstore = Chroma.from_documents(news_docs, embed_model)
    print("âœ… å‘é‡å­˜å‚¨åˆ›å»ºå®Œæˆ\n")

    # é…ç½®æ£€ç´¢å™¨çš„å…ƒæ•°æ®å­—æ®µ
    metadata_field_info = [
        AttributeInfo(
            name="title",
            description="æ–°é—»æ ‡é¢˜ï¼ˆå­—ç¬¦ä¸²ï¼‰",
            type="string",
        ),
        AttributeInfo(
            name="category",
            description="æ–°é—»åˆ†ç±»ï¼Œå¦‚ï¼šç¾å¦†æŠ¤è‚¤ã€ç¾é£Ÿæ¢åº—ã€æ—¶å°šç©¿æ­ã€æ—…æ¸¸æ”»ç•¥ç­‰ï¼ˆå­—ç¬¦ä¸²ï¼‰",
            type="string",
        ),
        AttributeInfo(
            name="author",
            description="æ–°é—»ä½œè€…æ˜µç§°ï¼ˆå­—ç¬¦ä¸²ï¼‰",
            type="string",
        ),
        AttributeInfo(
            name="likes_count",
            description="ç‚¹èµæ•°é‡ï¼ˆæ•´æ•°ï¼‰",
            type="integer",
        ),
        AttributeInfo(
            name="comments_count",
            description="è¯„è®ºæ•°é‡ï¼ˆæ•´æ•°ï¼‰",
            type="integer",
        ),
        AttributeInfo(
            name="shares_count",
            description="åˆ†äº«æ•°é‡ï¼ˆæ•´æ•°ï¼‰",
            type="integer",
        ),
        AttributeInfo(
            name="publish_date",
            description="å‘å¸ƒæ—¥æœŸï¼Œæ ¼å¼ä¸ºYYYY-MM-DDçš„å­—ç¬¦ä¸²",
            type="string",
        ),
        AttributeInfo(
            name="publish_day",
            description="å‘å¸ƒæ—¥æœŸçš„å¤©æ•°ï¼ˆæ•´æ•°ï¼Œ1-31ï¼‰",
            type="integer",
        ),
        AttributeInfo(
            name="tags",
            description="æ–°é—»æ ‡ç­¾ï¼Œå¤šä¸ªæ ‡ç­¾ç”¨é€—å·åˆ†éš”çš„å­—ç¬¦ä¸²",
            type="string",
        ),
        AttributeInfo(
            name="region",
            description="å‘å¸ƒåœ°åŒºï¼ˆå­—ç¬¦ä¸²ï¼‰",
            type="string",
        ),
    ]

    # åˆ›å»ºè‡ªæŸ¥è¯¢æ£€ç´¢å™¨
    print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–Self-Query Retriever...")

    llm = ChatDeepSeek(
        model="deepseek-chat", 
        temperature=0,
        api_key=os.getenv("DEEPSEEK_API_KEY")
    )

    retriever = SelfQueryRetriever.from_llm(
        llm=llm,                                    # è¯­è¨€æ¨¡å‹ï¼šç”¨äºç†è§£æŸ¥è¯¢æ„å›¾å¹¶ç”Ÿæˆç»“æ„åŒ–æŸ¥è¯¢
        vectorstore=vectorstore,                    # å‘é‡å­˜å‚¨ï¼šå­˜å‚¨æ–‡æ¡£å‘é‡å’Œå…ƒæ•°æ®çš„æ•°æ®åº“
        document_contents="åŒ…å«å°çº¢ä¹¦çƒ­ç‚¹æ–°é—»çš„æ ‡é¢˜ã€åˆ†ç±»ã€ä½œè€…ã€äº’åŠ¨æ•°æ®ç­‰ä¿¡æ¯",  # æ–‡æ¡£å†…å®¹æè¿°ï¼šå¸®åŠ©LLMç†è§£æ–‡æ¡£ç»“æ„
        metadata_field_info=metadata_field_info,   # å…ƒæ•°æ®å­—æ®µä¿¡æ¯ï¼šå®šä¹‰å¯æŸ¥è¯¢çš„å…ƒæ•°æ®å­—æ®µåŠå…¶ç±»å‹
        enable_limit=True,                          # å¯ç”¨é™åˆ¶ï¼šå…è®¸åœ¨æŸ¥è¯¢ä¸­æŒ‡å®šè¿”å›ç»“æœæ•°é‡
        verbose=True,                               # è¯¦ç»†è¾“å‡ºï¼šæ˜¾ç¤ºæŸ¥è¯¢å¤„ç†çš„è¯¦ç»†è¿‡ç¨‹ä¿¡æ¯
    )
    print("âœ… Self-Query Retriever åˆå§‹åŒ–å®Œæˆ\n")

    # æ‰§è¡Œç¤ºä¾‹æŸ¥è¯¢
    queries = [
        "æ‰¾å‡ºç‚¹èµæ•°è¶…è¿‡20000çš„çƒ­é—¨æ–°é—»",
        "æ˜¾ç¤ºç¾å¦†æŠ¤è‚¤ç±»åˆ«çš„æ–°é—»",
        "æŸ¥æ‰¾æ¥è‡ªæˆéƒ½åœ°åŒºçš„ç¾é£Ÿç›¸å…³å†…å®¹",
        "æ‰¾å‡ºå‘å¸ƒæ—¥æœŸå¤©æ•°å¤§äº13çš„æ–°é—»",
        "æ˜¾ç¤ºè¯„è®ºæ•°æœ€å¤šçš„æ—…æ¸¸æ”»ç•¥",
        "æŸ¥æ‰¾åŒ…å«'æ¨è'æ ‡ç­¾çš„æ–°é—»",
    ]

    # æ‰§è¡ŒæŸ¥è¯¢å¹¶è¾“å‡ºç»“æœ
    for query in queries:
        print(f"\n{'='*50}")
        print(f"ğŸ” æŸ¥è¯¢ï¼š{query}")
        print(f"{'='*50}")

        try:
            results = retriever.invoke(query)

            if not results:
                print("âŒ æœªæ‰¾åˆ°åŒ¹é…çš„æ–°é—»")
                continue

            print(f"âœ… æ‰¾åˆ° {len(results)} æ¡åŒ¹é…çš„æ–°é—»ï¼š\n")

            for i, doc in enumerate(results, 1):
                print(f"ğŸ“° æ–°é—» {i}:")
                print(f"   æ ‡é¢˜ï¼š{doc.metadata['title']}")
                print(f"   åˆ†ç±»ï¼š{doc.metadata['category']}")
                print(f"   ä½œè€…ï¼š{doc.metadata['author']}")
                print(f"   åœ°åŒºï¼š{doc.metadata['region']}")
                print(f"   å‘å¸ƒæ—¥æœŸï¼š{doc.metadata['publish_date']}")
                print(
                    f"   ç‚¹èµï¼š{doc.metadata['likes_count']} | è¯„è®ºï¼š{doc.metadata['comments_count']} | åˆ†äº«ï¼š{doc.metadata['shares_count']}"
                )
                print(f"   æ ‡ç­¾ï¼š{doc.metadata['tags']}")
                print(f"   å†…å®¹é¢„è§ˆï¼š{doc.page_content[:50]}...")
                print(f"   {'-'*40}")

        except Exception as e:
            print(f"âŒ æŸ¥è¯¢å‡ºé”™ï¼š{str(e)}")
            continue

    print(f"\n{'='*50}")
    print("ğŸ‰ Self-Query Retriever ç¤ºä¾‹æ¼”ç¤ºå®Œæˆï¼")
    print(f"{'='*50}")


if __name__ == "__main__":
    main()
