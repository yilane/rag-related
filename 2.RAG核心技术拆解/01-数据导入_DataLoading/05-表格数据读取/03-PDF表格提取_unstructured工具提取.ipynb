{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化 PDF文件路径\n",
    "pdf_path = \"../../90-文档_Data/复杂PDF/billionaires_page-1-5.pdf\"\n",
    "\n",
    "# # 导入 LlamaIndex 相关模块\n",
    "# from llama_index.core import Settings\n",
    "# from llama_index.llms.openai import OpenAI\n",
    "# from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "# from dotenv import load_dotenv\n",
    "\n",
    "# # 全局设置\n",
    "# load_dotenv()\n",
    "# Settings.llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "# Settings.embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理文档  移除页眉页脚 方法\n",
    "import fitz  # PyMuPDF\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "def remove_header_footer(input_pdf_path):\n",
    "    \"\"\"\n",
    "    使用模式识别从PDF文件的每一页中移除页眉和页脚\n",
    "    \n",
    "    参数：\n",
    "        input_pdf_path: 输入PDF文件的路径\n",
    "    \"\"\"\n",
    "    # 打开输入的PDF\n",
    "    doc = fitz.open(input_pdf_path)\n",
    "    \n",
    "    print(f\"PDF共有 {len(doc)} 页\")\n",
    "    \n",
    "    if len(doc) < 2:\n",
    "        print(\"警告：PDF少于2页，模式检测可能不可靠。\")\n",
    "    \n",
    "    # 步骤1：分析文本元素的位置以识别页眉和页脚\n",
    "    # 这种方法使用更复杂的方法来查看文本位置\n",
    "    \n",
    "    # 获取每页的尺寸\n",
    "    page_sizes = [(page.rect.width, page.rect.height) for page in doc]\n",
    "    \n",
    "    # 首先，分析所有页面上的文本位置\n",
    "    top_blocks = []  # 存储顶部区域的块\n",
    "    bottom_blocks = []  # 存储底部区域的块\n",
    "    \n",
    "    # 定义页面的哪个百分比应被视为页眉/页脚\n",
    "    header_region = 0.15  # 顶部15%\n",
    "    footer_region = 0.15  # 底部15%\n",
    "    \n",
    "    print(f\"分析顶部{header_region*100}%的页眉和底部{footer_region*100}%的页脚\")\n",
    "    \n",
    "    # 第一遍：收集位置信息\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        width, height = page_sizes[page_num]\n",
    "        \n",
    "        print(f\"\\n第 {page_num+1} 页 ({width}x{height}):\")\n",
    "        \n",
    "        # 提取带有位置信息的文本\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        \n",
    "        # 处理每个文本块\n",
    "        for block in blocks:\n",
    "            if block.get(\"type\") == 0:  # 文本块\n",
    "                for line in block.get(\"lines\", []):\n",
    "                    for span in line.get(\"spans\", []):\n",
    "                        text = span.get(\"text\", \"\").strip()\n",
    "                        if not text:\n",
    "                            continue\n",
    "                            \n",
    "                        # 获取位置信息\n",
    "                        bbox = span.get(\"bbox\")  # (x0, y0, x1, y1)\n",
    "                        if not bbox:\n",
    "                            continue\n",
    "                            \n",
    "                        # 检查是否在页眉区域\n",
    "                        y0 = bbox[1]\n",
    "                        y1 = bbox[3]\n",
    "                        \n",
    "                        # 在页眉区域？\n",
    "                        if y0 < height * header_region:\n",
    "                            top_blocks.append({\n",
    "                                \"text\": text,\n",
    "                                \"page\": page_num,\n",
    "                                \"bbox\": bbox,\n",
    "                                \"rel_pos\": y0 / height  # 相对位置\n",
    "                            })\n",
    "                            print(f\"页眉候选：'{text[:30]}...' 位置y={y0:.1f}\")\n",
    "                        \n",
    "                        # 在页脚区域？\n",
    "                        if y1 > height * (1 - footer_region):\n",
    "                            bottom_blocks.append({\n",
    "                                \"text\": text,\n",
    "                                \"page\": page_num,\n",
    "                                \"bbox\": bbox,\n",
    "                                \"rel_pos\": y1 / height  # 相对位置\n",
    "                            })\n",
    "                            print(f\"页脚候选：'{text[:30]}...' 位置y={y1:.1f}\")\n",
    "    \n",
    "    # 第二遍：识别位置和内容中的模式\n",
    "    # 按相似的垂直位置（相对于页面高度）分组\n",
    "    \n",
    "    def group_by_position(blocks, threshold=0.02):\n",
    "        \"\"\"将出现在相似位置的块分组\"\"\"\n",
    "        position_groups = defaultdict(list)\n",
    "        \n",
    "        # 首先按相似的y位置对块进行分组\n",
    "        for block in blocks:\n",
    "            # 将位置四舍五入到最接近的阈值进行分组\n",
    "            pos_key = round(block[\"rel_pos\"] / threshold) * threshold\n",
    "            position_groups[pos_key].append(block)\n",
    "        \n",
    "        return position_groups\n",
    "    \n",
    "    # 按位置对页眉和页脚进行分组\n",
    "    header_groups = group_by_position(top_blocks)\n",
    "    footer_groups = group_by_position(bottom_blocks)\n",
    "    \n",
    "    print(\"\\n页眉位置组:\")\n",
    "    for pos, blocks in header_groups.items():\n",
    "        print(f\"距顶部 {pos*100:.1f}% 的位置: {len(blocks)} 次出现\")\n",
    "        # 统计每个文本的出现次数\n",
    "        text_counts = defaultdict(int)\n",
    "        for block in blocks:\n",
    "            text_counts[block[\"text\"]] += 1\n",
    "        \n",
    "        # 查找在此位置重复出现的文本\n",
    "        for text, count in text_counts.items():\n",
    "            if count >= max(2, len(doc) * 0.5):  # 在至少50%的页面上出现\n",
    "                print(f\"  - '{text[:50]}...' 出现 {count} 次\")\n",
    "    \n",
    "    print(\"\\n页脚位置组:\")\n",
    "    for pos, blocks in footer_groups.items():\n",
    "        print(f\"距顶部 {pos*100:.1f}% 的位置: {len(blocks)} 次出现\")\n",
    "        # 统计每个文本的出现次数\n",
    "        text_counts = defaultdict(int)\n",
    "        for block in blocks:\n",
    "            text_counts[block[\"text\"]] += 1\n",
    "        \n",
    "        # 查找在此位置重复出现的文本\n",
    "        for text, count in text_counts.items():\n",
    "            if count >= max(2, len(doc) * 0.5):  # 在至少50%的页面上出现\n",
    "                print(f\"  - '{text[:50]}...' 出现 {count} 次\")\n",
    "    \n",
    "    # 定义页眉/页脚移除标准\n",
    "    # 我们将移除满足以下条件的块:\n",
    "    # 1. 在多个页面的相似位置出现（至少50%的页面）\n",
    "    # 2. 包含相同或相似的文本\n",
    "    \n",
    "    # 步骤3：创建一个移除页眉和页脚的新文档\n",
    "    new_doc = fitz.open()\n",
    "    \n",
    "    # 跟踪我们确定为页眉/页脚的位置\n",
    "    header_positions = []\n",
    "    for pos, blocks in header_groups.items():\n",
    "        text_counts = defaultdict(int)\n",
    "        for block in blocks:\n",
    "            text_counts[block[\"text\"]] += 1\n",
    "        \n",
    "        # 如果任何文本在此位置至少出现在50%的页面上\n",
    "        if any(count >= max(2, len(doc) * 0.5) for count in text_counts.values()):\n",
    "            header_positions.append(pos)\n",
    "    \n",
    "    footer_positions = []\n",
    "    for pos, blocks in footer_groups.items():\n",
    "        text_counts = defaultdict(int)\n",
    "        for block in blocks:\n",
    "            text_counts[block[\"text\"]] += 1\n",
    "        \n",
    "        # 如果任何文本在此位置至少出现在50%的页面上\n",
    "        if any(count >= max(2, len(doc) * 0.5) for count in text_counts.values()):\n",
    "            footer_positions.append(pos)\n",
    "    \n",
    "    print(f\"\\n识别出 {len(header_positions)} 个页眉位置和 {len(footer_positions)} 个页脚位置\")\n",
    "    \n",
    "    # 创建一个没有页眉和页脚的新PDF\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc[page_num]\n",
    "        width, height = page_sizes[page_num]\n",
    "        \n",
    "        # 创建一个新页面\n",
    "        new_page = new_doc.new_page(width=width, height=height)\n",
    "        \n",
    "        # 编辑页眉和页脚\n",
    "        blocks_to_redact = []\n",
    "        \n",
    "        # 获取此页的所有块\n",
    "        blocks = page.get_text(\"dict\")[\"blocks\"]\n",
    "        \n",
    "        for block in blocks:\n",
    "            if block.get(\"type\") == 0:  # 文本块\n",
    "                for line in block.get(\"lines\", []):\n",
    "                    for span in line.get(\"spans\", []):\n",
    "                        bbox = span.get(\"bbox\")\n",
    "                        if not bbox:\n",
    "                            continue\n",
    "                            \n",
    "                        # 相对位置\n",
    "                        y0_rel = bbox[1] / height\n",
    "                        y1_rel = bbox[3] / height\n",
    "                        \n",
    "                        # 检查是否在页眉位置\n",
    "                        is_header = any(abs(y0_rel - pos) < 0.02 for pos in header_positions)\n",
    "                        # 检查是否在页脚位置\n",
    "                        is_footer = any(abs(y1_rel - pos) < 0.02 for pos in footer_positions)\n",
    "                        \n",
    "                        if is_header or is_footer:\n",
    "                            # 为此跨度创建编辑注释\n",
    "                            redact_rect = fitz.Rect(bbox)\n",
    "                            page.add_redact_annot(redact_rect)\n",
    "        \n",
    "        # 应用编辑\n",
    "        page.apply_redactions()\n",
    "        \n",
    "        # 复制清理后的页面\n",
    "        new_page.show_pdf_page(new_page.rect, doc, page_num)\n",
    "    \n",
    "    output_dir = \"output\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_filename = os.path.basename(input_pdf_path).replace(\".pdf\", \"_no_header_footer.pdf\")\n",
    "    output_pdf_path = os.path.join(output_dir, output_filename)\n",
    "\n",
    "    # 保存输出\n",
    "    new_doc.save(output_pdf_path)\n",
    "    new_doc.close()\n",
    "    doc.close()\n",
    "    \n",
    "    print(f\"\\nPDF处理成功。已保存到 {output_pdf_path}\")\n",
    "    return output_pdf_path\n",
    "\n",
    "# 执行过滤页眉页脚方法 返回新的PDF文件路径\n",
    "filter_pdf_path = remove_header_footer(pdf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. unstructured 表格提取\n",
    "**优化策略**\n",
    "1. 使用cleaners过滤页脚信息\n",
    "2. 通过coordinates去除页脚\n",
    "3. 通过metadata识别并排除页脚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "elements = partition_pdf(\n",
    "    filter_pdf_path,\n",
    "    strategy=\"hi_res\",  # 保持高精度策略\n",
    "    ocr_languages=[\"eng\"],  # 明确指定英语OCR，因为表格主要是英文\n",
    "    extract_images_in_pdf=False,  # 减少对图像的处理，专注于文本和表格\n",
    "    infer_table_structure=True,  # 保持表格结构推断\n",
    "    max_characters=100000,  # 增加处理字符数上限，确保完整捕获\n",
    "    include_page_breaks=True,  # 添加页面分隔符，便于后续处理\n",
    "    pdf_image_dpi=300,  # 提高DPI，增强特殊符号识别\n",
    "    detection_model_name=\"llm\",  # 使用基于LLM的表格检测模型可能提高准确性\n",
    "    image_output_directory_path=None,  # 不输出中间图像\n",
    "    ocr_kwargs={\"preserve_interword_spaces\": True}  # 保留词间空格，提高格式保留度\n",
    ")  # 解析PDF文档\n",
    "\n",
    "# 创建一个元素ID到元素的映射\n",
    "element_map = {element.id: element for element in elements if hasattr(element, \"id\")}\n",
    "\n",
    "# 创建一个元素索引到元素的映射\n",
    "element_index_map = {i: element for i, element in enumerate(elements)}\n",
    "\n",
    "# 处理表格数据\n",
    "for i, element in enumerate(elements):\n",
    "    if element.category == \"Table\":\n",
    "        print(\"\\n表格数据:\")\n",
    "        print(\"表格元数据:\", vars(element.metadata))\n",
    "        print(\"表格内容:\")\n",
    "        # 打印表格内容\n",
    "        # 检查表格是否有HTML结构\n",
    "        if hasattr(element, \"metadata\") and hasattr(element.metadata, \"text_as_html\"):\n",
    "            print(\"表格HTML结构:\")\n",
    "            print(element.metadata.text_as_html)\n",
    "        else:\n",
    "            print(\"表格结构:\")\n",
    "            print(element.text)\n",
    "\n",
    "        # 获取并打印父节点信息\n",
    "        parent_id = getattr(element.metadata, \"parent_id\", None)\n",
    "        if parent_id and parent_id in element_map:\n",
    "            parent_element = element_map[parent_id]\n",
    "            # 跳过页眉页脚的父节点\n",
    "            if parent_element.category not in [\"Header\", \"Footer\"]:\n",
    "                print(\"\\n父节点信息:\")\n",
    "                print(f\"类型: {parent_element.category}\")\n",
    "                print(f\"内容: {parent_element.text}\")\n",
    "                if hasattr(parent_element, \"metadata\"):\n",
    "                    print(f\"父节点元数据: {vars(parent_element.metadata)}\")\n",
    "        else:\n",
    "            print(f\"未找到父节点 (ID: {parent_id})\")\n",
    "            # 如果未找到父节点,从前3个节点中寻找Title\n",
    "            title_content = None\n",
    "            for j in range(max(0, i - 3), i):\n",
    "                prev_element = element_index_map.get(j)\n",
    "                if prev_element and prev_element.category == \"Title\":\n",
    "                    title_content = prev_element.text\n",
    "                    break\n",
    "\n",
    "            if title_content:\n",
    "                print(f\"\\n找到最近的标题内容:\")\n",
    "                print(f\"类型: {prev_element.category}\")\n",
    "                print(f\"内容: {prev_element.text}\")\n",
    "                if hasattr(prev_element, \"metadata\"):\n",
    "                    print(f\"最近标题元数据: {vars(prev_element.metadata)}\")\n",
    "            else:\n",
    "                print(\"\\n未找到相关标题内容\")\n",
    "        print(\"-\" * 100)\n",
    "\n",
    "# 将表格数据和标题内容转换为Markdown格式\n",
    "import re\n",
    "import os\n",
    "\n",
    "print(\"\\n开始生成Markdown文件...\")\n",
    "\n",
    "# 创建一个列表来存储所有表格及其相关信息\n",
    "tables_with_context = []\n",
    "\n",
    "for i, element in enumerate(elements):\n",
    "    if element.category == \"Table\":\n",
    "        table_content = element.text\n",
    "        table_html = getattr(element.metadata, \"text_as_html\", None)\n",
    "\n",
    "        # 尝试获取标题信息\n",
    "        title_content = None\n",
    "        parent_id = getattr(element.metadata, \"parent_id\", None)\n",
    "\n",
    "        # 方法1: 通过父节点获取标题\n",
    "        if parent_id and parent_id in element_map:\n",
    "            parent_element = element_map[parent_id]\n",
    "            if parent_element.category not in [\"Header\", \"Footer\"]:\n",
    "                title_content = parent_element.text\n",
    "\n",
    "        # 方法2: 如果没有找到父节点标题，从前3个节点中寻找Title\n",
    "        if not title_content:\n",
    "            for j in range(max(0, i - 3), i):\n",
    "                prev_element = element_index_map.get(j)\n",
    "                if prev_element and prev_element.category == \"Title\":\n",
    "                    title_content = prev_element.text\n",
    "                    break\n",
    "\n",
    "        # 如果仍然没有标题，使用默认标题\n",
    "        if not title_content:\n",
    "            title_content = f\"表格 {len(tables_with_context) + 1}\"\n",
    "\n",
    "        # 将表格和标题添加到列表中\n",
    "        tables_with_context.append(\n",
    "            {\n",
    "                \"title\": title_content.strip(),\n",
    "                \"content\": table_content,\n",
    "                \"html\": table_html,\n",
    "            }\n",
    "        )\n",
    "\n",
    "# 生成Markdown文件\n",
    "markdown_content = \"# PDF表格提取结果\\n\\n\"\n",
    "\n",
    "for i, table_info in enumerate(tables_with_context, 1):\n",
    "    # 添加标题\n",
    "    markdown_content += f\"## {table_info['title']}\\n\\n\"\n",
    "\n",
    "    # 将HTML表格转换为Markdown表格格式\n",
    "    if table_info[\"html\"]:\n",
    "        # 提取表格内容\n",
    "        html_content = table_info[\"html\"]\n",
    "\n",
    "        # 使用正则表达式提取表格行和单元格\n",
    "        rows = re.findall(r\"<tr.*?>(.*?)</tr>\", html_content, re.DOTALL)\n",
    "\n",
    "        markdown_table = \"\"\n",
    "        header_processed = False\n",
    "\n",
    "        for row in rows:\n",
    "            # 提取单元格内容\n",
    "            cells = re.findall(r\"<t[hd].*?>(.*?)</t[hd]>\", row, re.DOTALL)\n",
    "            if cells:\n",
    "                # 清理单元格内容中的HTML标签\n",
    "                cleaned_cells = [re.sub(r\"<.*?>\", \"\", cell).strip() for cell in cells]\n",
    "\n",
    "                # 添加表格行\n",
    "                markdown_table += \"| \" + \" | \".join(cleaned_cells) + \" |\\n\"\n",
    "\n",
    "                # 添加表头分隔符\n",
    "                if not header_processed:\n",
    "                    markdown_table += (\n",
    "                        \"| \" + \" | \".join([\"---\"] * len(cleaned_cells)) + \" |\\n\"\n",
    "                    )\n",
    "                    header_processed = True\n",
    "\n",
    "        markdown_content += markdown_table + \"\\n\"\n",
    "    else:\n",
    "        # 如果没有HTML，使用原始文本内容\n",
    "        markdown_content += f\"```\\n{table_info['content']}\\n```\\n\\n\"\n",
    "\n",
    "# 保存Markdown文件\n",
    "output_dir = \"output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, \"extracted_tables.md\")\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(markdown_content)\n",
    "\n",
    "print(f\"Markdown文件已生成: {output_file}\")\n",
    "print(f\"共提取了 {len(tables_with_context)} 个表格\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 使用LlamaParse解析PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_parse import LlamaParse\n",
    "import time\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# 记录开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "# 使用LlamaParse解析PDF\n",
    "parser = LlamaParse(\n",
    "    result_type=\"markdown\",\n",
    ")\n",
    "\n",
    "# 加载并解析PDF文档\n",
    "documents = parser.load_data(filter_pdf_path)\n",
    "\n",
    "# 记录结束时间\n",
    "end_time = time.time()\n",
    "print(f\"PDF解析耗时: {end_time - start_time:.2f}秒\")\n",
    "\n",
    "# 打印过滤后的解析结果\n",
    "print(\"\\n文档内容:\")\n",
    "for i, doc in enumerate(documents, 1):\n",
    "    print(f\"\\n文档 {i} 内容:\")\n",
    "    print(doc.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_LlamaIndex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
